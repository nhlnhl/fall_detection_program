{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('../dataset/training_data_RNN.csv', delimiter=',', dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 36\n",
    "n_step = 1500\n",
    "n_hidden = 128\n",
    "n_class = 11\n",
    "n_batch = int(data.shape[0] / n_step)\n",
    "\n",
    "learning_rate = 0.001\n",
    "total_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.005000e+00  2.290000e-01 -8.300000e-02 ...  3.159150e+02\n",
      "    2.108154e+03  4.500000e+01]\n",
      "  [-1.005000e+00  2.290000e-01 -8.300000e-02 ...  3.159150e+02\n",
      "    2.108154e+03  4.500000e+01]\n",
      "  [-1.005000e+00  2.290000e-01 -8.300000e-02 ...  3.159150e+02\n",
      "    2.108154e+03  4.500000e+01]\n",
      "  ...\n",
      "  [-1.800000e-01 -1.008000e+00  5.900000e-02 ...  4.880000e-01\n",
      "    2.538408e+03  1.180000e+02]\n",
      "  [-1.800000e-01 -1.008000e+00  5.900000e-02 ...  3.050000e-01\n",
      "    2.538408e+03  1.600000e+02]\n",
      "  [-1.800000e-01 -1.008000e+00  5.900000e-02 ...  3.050000e-01\n",
      "    2.538408e+03  1.600000e+02]]\n",
      "\n",
      " [[-1.017000e+00  1.280000e-01 -1.040000e-01 ...  4.207000e+00\n",
      "    1.945644e+03  1.200000e+02]\n",
      "  [-1.017000e+00  1.280000e-01 -1.040000e-01 ...  4.207000e+00\n",
      "    1.945644e+03  1.200000e+02]\n",
      "  [-1.023000e+00  1.080000e-01 -8.600000e-02 ...  1.274400e+01\n",
      "    1.945644e+03 -1.610000e+02]\n",
      "  ...\n",
      "  [-1.970000e-01 -9.860000e-01  7.900000e-02 ...  6.100000e-02\n",
      "    5.676500e+01  4.000000e+01]\n",
      "  [-1.970000e-01 -9.860000e-01  7.900000e-02 ...  6.100000e-02\n",
      "    5.676500e+01  4.000000e+01]\n",
      "  [-1.970000e-01 -9.860000e-01  7.900000e-02 ...  6.100000e-02\n",
      "    5.676500e+01  4.000000e+01]]\n",
      "\n",
      " [[-1.016000e+00  1.980000e-01 -2.700000e-02 ...  5.671000e+00\n",
      "    4.394750e+02  1.560000e+02]\n",
      "  [-1.016000e+00  1.980000e-01 -2.700000e-02 ...  5.671000e+00\n",
      "    4.394750e+02  1.560000e+02]\n",
      "  [-1.017000e+00  1.890000e-01 -3.400000e-02 ... -1.847600e+01\n",
      "    4.394750e+02 -5.000000e+00]\n",
      "  ...\n",
      "  [-3.630000e-01  9.430000e-01 -6.100000e-02 ...  6.100000e-01\n",
      "    8.783240e+02  2.900000e+01]\n",
      "  [-3.630000e-01  9.430000e-01 -6.100000e-02 ...  6.100000e-01\n",
      "    8.783240e+02  2.900000e+01]\n",
      "  [-3.630000e-01  9.430000e-01 -6.100000e-02 ...  6.100000e-01\n",
      "    8.783240e+02  2.900000e+01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-9.810000e-01  4.230000e-01 -1.800000e-02 ... -1.042700e+01\n",
      "    1.433867e+03  1.490000e+02]\n",
      "  [-9.810000e-01  4.230000e-01 -1.800000e-02 ... -1.042700e+01\n",
      "    1.433867e+03  1.490000e+02]\n",
      "  [-9.810000e-01  4.230000e-01 -1.800000e-02 ... -1.042700e+01\n",
      "    1.433867e+03  1.490000e+02]\n",
      "  ...\n",
      "  [-9.560000e-01  3.100000e-02 -3.820000e-01 ...  1.951000e+00\n",
      "    1.520878e+03  2.200000e+02]\n",
      "  [-9.560000e-01  3.100000e-02 -3.820000e-01 ...  1.951000e+00\n",
      "    1.520878e+03  2.200000e+02]\n",
      "  [-9.560000e-01  3.100000e-02 -3.820000e-01 ...  1.951000e+00\n",
      "    1.520878e+03  2.200000e+02]]\n",
      "\n",
      " [[-1.056000e+00 -5.630000e-01  1.670000e-01 ... -1.073200e+01\n",
      "    1.995913e+03  1.360000e+02]\n",
      "  [-8.380000e-01  3.610000e-01 -6.980000e-01 ... -2.432900e+01\n",
      "    1.995913e+03  1.230000e+02]\n",
      "  [-9.840000e-01  5.210000e-01 -6.260000e-01 ... -3.219500e+01\n",
      "    1.995913e+03  1.340000e+02]\n",
      "  ...\n",
      "  [-1.272000e+00  3.110000e-01 -7.390000e-01 ... -1.285980e+02\n",
      "    1.316104e+03  1.530000e+02]\n",
      "  [-1.329000e+00  1.730000e-01 -8.060000e-01 ... -1.617070e+02\n",
      "    1.316104e+03  7.160000e+02]\n",
      "  [-1.329000e+00  1.730000e-01 -8.060000e-01 ... -6.097600e+01\n",
      "    1.316104e+03  6.990000e+02]]\n",
      "\n",
      " [[-3.080000e-01 -1.000000e+00 -6.800000e-02 ...  3.603050e+02\n",
      "    3.837070e+02 -2.048000e+03]\n",
      "  [-3.550000e-01 -9.750000e-01 -1.360000e-01 ...  2.411590e+02\n",
      "    3.837070e+02 -1.473000e+03]\n",
      "  [-2.680000e-01 -9.630000e-01 -1.900000e-02 ... -1.563420e+02\n",
      "    3.837070e+02 -8.540000e+02]\n",
      "  ...\n",
      "  [-2.680000e-01 -7.910000e-01  5.890000e-01 ...  3.660000e-01\n",
      "    5.750980e+02  6.400000e+01]\n",
      "  [-2.700000e-01 -7.940000e-01  5.860000e-01 ...  1.830000e-01\n",
      "    5.750980e+02  1.480000e+02]\n",
      "  [-2.700000e-01 -7.940000e-01  5.860000e-01 ...  1.220000e-01\n",
      "    5.750980e+02  6.000000e+01]]]\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "(134, 1500, 36)\n",
      "(134, 11)\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:, :n_input]\n",
    "x_data = x_data.reshape(n_batch, n_step, n_input)\n",
    "y_data_temp = data[:, -1]\n",
    "\n",
    "sess = tf.Session()\n",
    "y_data_temp = np.subtract(y_data_temp, np.ones(y_data_temp.shape))\n",
    "y_data_temp = tf.one_hot(y_data_temp, depth=n_class).eval(session=sess)\n",
    "\n",
    "y_data = np.zeros([n_batch, n_class])\n",
    "for i in range(n_batch):\n",
    "    y_data[i] = y_data_temp[1500 * i]\n",
    "\n",
    "print(x_data)\n",
    "print(y_data)\n",
    "print(x_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\a jin cho\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None, n_step, n_input])\n",
    "Y = tf.placeholder(tf.float32, [None, n_class])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([n_hidden, n_class]))\n",
    "b = tf.Variable(tf.random_normal([n_class]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-e712b13936c2>:2: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-6-e712b13936c2>:4: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BasicRNNCell, BasicLSTMCell, GRUCell\n",
    "cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "\n",
    "outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "outputs = outputs[-1]\n",
    "model = tf.matmul(outputs, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "tf.summary.scalar('cost', cost)\n",
    "tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Avg. cost = 0.129\n",
      "Accuracy = 0.15671642\n",
      "Epoch: 0002 Avg. cost = 0.122\n",
      "Accuracy = 0.14925373\n",
      "Epoch: 0003 Avg. cost = 0.116\n",
      "Accuracy = 0.15671642\n",
      "Epoch: 0004 Avg. cost = 0.111\n",
      "Accuracy = 0.1641791\n",
      "Epoch: 0005 Avg. cost = 0.106\n",
      "Accuracy = 0.1641791\n",
      "Epoch: 0006 Avg. cost = 0.103\n",
      "Accuracy = 0.14925373\n",
      "Epoch: 0007 Avg. cost = 0.100\n",
      "Accuracy = 0.1641791\n",
      "Epoch: 0008 Avg. cost = 0.096\n",
      "Accuracy = 0.1641791\n",
      "Epoch: 0009 Avg. cost = 0.093\n",
      "Accuracy = 0.17910448\n",
      "Epoch: 0010 Avg. cost = 0.090\n",
      "Accuracy = 0.18656716\n",
      "Epoch: 0011 Avg. cost = 0.088\n",
      "Accuracy = 0.18656716\n",
      "Epoch: 0012 Avg. cost = 0.086\n",
      "Accuracy = 0.18656716\n",
      "Epoch: 0013 Avg. cost = 0.083\n",
      "Accuracy = 0.19402985\n",
      "Epoch: 0014 Avg. cost = 0.081\n",
      "Accuracy = 0.19402985\n",
      "Epoch: 0015 Avg. cost = 0.079\n",
      "Accuracy = 0.18656716\n",
      "Epoch: 0016 Avg. cost = 0.078\n",
      "Accuracy = 0.18656716\n",
      "Epoch: 0017 Avg. cost = 0.076\n",
      "Accuracy = 0.19402985\n",
      "Epoch: 0018 Avg. cost = 0.075\n",
      "Accuracy = 0.20149253\n",
      "Epoch: 0019 Avg. cost = 0.072\n",
      "Accuracy = 0.20895523\n",
      "Epoch: 0020 Avg. cost = 0.070\n",
      "Accuracy = 0.20895523\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter('./logs', sess.graph)\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    total_cost = 0\n",
    "\n",
    "    _, cost_val = sess.run([optimizer, cost], feed_dict={X: x_data, Y: y_data})\n",
    "    total_cost += cost_val\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'Avg. cost =', '{:.3f}'.format(total_cost / n_batch))\n",
    "    print('Accuracy =', sess.run(accuracy, feed_dict={X: x_data, Y: y_data}))\n",
    "    \n",
    "    summary = sess.run(merged, feed_dict={X: x_data, Y: y_data})\n",
    "    writer.add_summary(summary, global_step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.20895523\n"
     ]
    }
   ],
   "source": [
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "print('Accuracy =', sess.run(accuracy, feed_dict={X: x_data, Y: y_data}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
